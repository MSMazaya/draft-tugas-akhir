\section{Latar Belakang}

\textit{Information Retrieval} (IR) adalah penemuan bahan seperti dokumen yang bersifat terstruktur yang memenuhi kebutuhan informasi dari dalam koleksi besar yang tersimpan di dalam komputer \parencite{inforetrieval}. IR saat ini sangat sering dilakukan contohnya dalam pencarian informasi berkaitan dengan representasi, penyimpanan, pengaturan, dokumen, halaman web, katalog online, catatan, dan objek multimedia. Salah satu aplikasi yang membantu dalam melakukan hal tersebut adalah Elastic Search.

\textit{Elasticsearch} merupakan mesin pencarian dan analitik terdistribusi yang dibangun di Apache Lucene. \textit{Elasticsearch} telah dengan cepat menjadi mesin pencari paling populer dan biasa digunakan untuk analisis log, pencarian teks lengkap, inteligensi keamanan, analisis bisnis, dan kasus penggunaan inteligensi operasional \parencite{elasticsearch}.

Proses \textit{Elastic Search} menggunakan JVM. Umumnya pada \textit{Elastic Search}, hampir 50 persen memori yang tersedia akan dialokasikan ke JVM. Pemrosesan Elasticsearch umumnya dilakukan pada memori. Sehingga, berdasarkan riset (Mukul Dev; Rahul Kapoor; B Balamurugan), Pemrosesan data berukuran besar dalam in-memory computing pada JVM memakan sangat banyak memory. Dalam konteks \textit{Elastic Search}, mesin JVM memerlukan memakai memori karena Apache Lucene membutuhkan melakukan \textit{indexing} dan \textit{caching}. \textit{Elastic Search} sendiri merekomendasikan 50 persen memori dari sebuah host dialokasikan untuk JVM tempat \textit{Elastic Search} berjalan, dan 50 persen sisanya dipakai untuk sistem operasi dan keperluan aplikasi lain. Hal tersebut sangat diperlukan untuk memberikan performa maksimal terhadap \textit{information retrieval system} agar \textit{indexing} dan \textit{caching} dapat berjalan secara maksimal. Namun, pada kondisi nyatanya, pengunaan memori untuk \textit{caching} dan \textit{indexing} tidak efisien untuk semua jenis data dan kondisi. Sehingga, jika disederhanakan, data yang jarang dipakai adalah hal yang “opsional” untuk di-indeks dan di-\textit{cache}. Harapannya, penggunaan memori ini dapat digunakan oleh aplikasi atau keperluan lain yang lebih membutuhkan. Di sisi lain, proses \textit{indexing} sendiri sangat memakan sumber daya prosesor sehingga apabila ukuran \textit{cache} terlalu kecil hal ini akan berdampak menyibukkan mesin untuk memproses permintaan \textit{query} yang masuk. Penentuan alokasi memori terhadap \textit{Elastic Search} sehingga efisien adalah hal yang krusial terutama penentuan ini sangat memerlukan untuk beradaptasi dengan kebutuhan dan kondisi data yang ada.



% Hal ini menyebabkan \textit{Elastic Search} akan memakan memori sebanyak-banyaknya untuk dipakai \textit{caching}. Sedangkan, dalam segi kebutuhan, belum tentu semua data pada \textit{cache} akan dipakai. Ada kalanya waktu saat banyak terjadi \textit{miss} karena data yang dicari terlalu bervariasi. Atau kondisi lain seperti \textit{cost cache} yang terlalu besar dan tidak sebanding dengan pengunaan memori pada suatu \textit{Kubernetes Cluster}. Kondisi seperti itu tidak menjadi masalah ketika sebuah \textit{node} sedang kosong dan punya banyak memori. Namun, akan menjadi masalah ketika ada aplikasi lain yang ingin memakai bersama \textit{node} tersebut dan memori telah dipakai habis oleh \textit{Elastic Search}.

% Untuk menangani hal tersebut, Kubernetes sendiri sudah memiliki fitur bernama \textit{resource limit}. Fitur ini digunakan untuk membatasi pengunaan sumber daya oleh sebuah aplikasi. Namun, \textit{resource limit} ini bersifat statik dan tidak adaptif. Jika ingin mengubahnya, diperlukan pengubahan konfigurasi melalui file \textit{deployment} atau perintah \textit{kubectl}. Sedangkan, performa suatu \textit{information retrieval} sangat dinamis dan apabila ingin mengontrol pengunaan memori berdasarkan performa membutuhkan alat yang sangat dinamis.

% Kubernetes sendiri sudah memiliki \textit{auto-scaler} yang dinamis. Pada \textit{auto-scaler} versi horizontal, komponen ini akan mereplikasi secara otomatis ketika performa memburuk. Namun, \textit{auto-scaler} ini akan mematikan dan menyalakan \textit{node} baru pada kluster \textit{Elastic Search}. Dan oleh karena itu, akan terjadi banyak \textit{balancing} dan replikasi \textit{shard} pada \textit{Elastic Search} yang menyebabkan banyak \textit{overhead} apabila terlalu sering terjadi penambahan atau pengurangan \textit{node} pada kluster \textit{Elastic Search}. Sedangkan, pada \textit{auto-scaler} versi vertikal, komponen ini masih dikembangkan oleh Kubernetes, dan mengharuskan Kubernetes untuk melakukan \textit{restart} pada \textit{node} yang di-\textit{scale} secara vertikal yang berarti kasusnya tidak jauh beda dengan \textit{scaling} secara horizontal.